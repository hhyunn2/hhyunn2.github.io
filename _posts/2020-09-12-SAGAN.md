# Self-Attention GAN Review

## 1. Intro

GAN이 처음 등장한 이후 많은 GAN 모델들이 나오게 되었습니다. 하지만 convolutional GAN들의 경우 multi-class 데이터셋에 대해서 학습을 진행하였을때 기하학적 혹은 구조적 패턴을 파악하지 못하여 이미지 클래스에 대한 모델링이 어렵다는 단점이 있습니다. 기존의 convolutional 필터의 경우 로컬한 정보들에 대해서는 잘 처리하지만 좀 더 큰 구조들에 대해서는 receptive fields가 커버하기 힘들기 때문입니다. 그렇다면 필터의 크기를 충분히 늘리면 되지 않을까하는 의문이 제기될 수 있습니다. 하지만 필터의 크기를 늘리게 된다면 계산적으로 효율성이 많이 떨어지기 때문에 학습에 어려움이 생길 수 있습니다. 따라서 Self-attention GAN(이하 SAGAN)은 그 이름에서도 알 수 있듯이 앞서 언급한 문제점들을 해결하고자 self-attention 개념을 응용해 효과적으로 이미지를 생성할 수 있도록 고안되었습니다. 아래의 그림처럼  SAGAN은 

<figure>
	<img src="{{ '/assets/images/sagan/intro.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [그림 1. SAGAN의 이미지 생성 모습] </figcaption>
</figure>

## 2. Architecture

### 2-1. Self-attention to the GAN

먼저 SAGAN 모델의 가장 핵심이라고 할 수 있는 attention module에 대해서 설명드리겠습니다. 이 attention module은 generator와 discriminator 모두에 활용되는 구조로서 그림 2와 같은 형태를 띄고 있습니다. 

Attention module은 convolution feature maps $x$가 input으로 들어오면서 시작이 됩니다. 이전 hidden layer의 이미지 features, $x$가 $f(x)=W_fx$와 $g(x)=W_gx$를 통하여 두 가지 feature spaces $f$와 $g$에 transform됩니다. 이러한 방식으로 만들어지는 값 $f(x)$와 $g(x)$를 행렬의 transpose를 적절하게 이용해 계산을 하게되면 $\beta_{j,i}=\frac{exp(s_{ij})}{\sum^N_{i=1}exp(s_{ij})}$, $s_{ij}=f(x_i)^Tg(x_j)$와 같은 식들이 도출됩니다.  $s_{ij}$의 경우 $f$, $g$ 두 feature spaces를 행렬곱으로 계산한 값이며 $\beta_{j,i}$의 경우 구한 $s_{ij}$들을 softmax 계산식에 넣은 결과값들입니다.  아래의 구조도를 살펴보면 구한 $\beta_{j,i}$값은 attention map이라고 볼 수 있겠습니다. 좀 더 쉽게 풀어쓰면 location i가 location j를 표현할때 미치는 영향을 설명하는 것이라고 생각하시면 될 것 같습니다. 

<figure>
	<img src="{{ '/assets/images/sagan/architecture.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [그림 2. SAGAN의 self-attention module 구조] </figcaption>
</figure> 

위의 구조에서 확인할 수 있듯이 softamax로 구해진 attention map을 $h$와 다시 결합을 하게 되는데 이때 사용되는 $h$ 역시 위에서의 $f$나 $g$처럼 파라미터인 $W_h$와의 곱을 통해 $h(x_i)=W_hx_i$식으로 구해진 값입니다. 이후 Attention map과 $h$를 결합하여  self-attention feature map을 뽑는 과정은 $o_j =v\left(\sum^N_{i=1}\beta_{j,i}h(x_i)\right)$라는 식으로 표현이 될 수 있겠습니다. 이때의 $v(x)$도 마찬가지로 $v(x_i)=W_vx_i$를 만족합니다. 

Self-attention feature map들까지 얻게 된다면 이를 활용해 최종 결과 $y_i=\gamma o_i+x_i$를 도출하게 됩니다. 이때 $\gamma$의 역할은 scale parameter, 즉 점차적으로 non-local한 정보에 더 가중치를 주는 역할로 0으로 initialize해주게 됩니다.

SAGAN의 adversarial loss function은 다음과 같습니다.
$$
\mathit{L}_D=-\mathbb{E}_{(x,y)\sim p_{data}}\left[\min(0,-1+D(x,y))\right]
-\mathbb{E}_{z\sim p_z,\; y\sim p_{data}}\left[\min(0,-1-D(G(z),y))\right] \\
\mathit{L}_D=-\mathbb{E}_{z\sim p_z,\; y\sim p_{data}}D(G(z),y)
$$


식을 보시면 generator와 discriminator 모두 attention module이 적용되었음을 확인할 수 있으며 hinge version의 adversarial loss가 활용되었음을 알 수 있습니다.



### 2-2. Methods to stabilize the training

Training 과정에서 GAN의 경우 안정적이지 못한 

