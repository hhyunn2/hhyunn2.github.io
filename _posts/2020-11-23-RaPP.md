---
title: "RAPP: Novelty Detection with Reconstruction Along Projection Pathway Review 리뷰"
category :
    - Novelty Detection
tag :
    - Novelty Detection
toc : true

---

# RAPP: Novelty Detection with Reconstruction Along Projection Pathway Review

## 1. Intro

Novelty Detection은 학습데이터에서 특정 데이터 샘플이 outlier인지를 확인하는 방법입니다. Deep autoencoders와 reconstruction error의 사용으로 인해 novelty detection을 진행해왔습니다. 이번 $R_APP$ 모델은 hidden activation values를 활용하여  좀 더 novelty 샘플들에 대한 감지를 잘 해낼 수 있도록한 모델입니다. 본 모델은 기존의 입력값과 autoencoder를 통과한 결과값을 비교하는 것을 넘어서 나온 결과값을 다시 autoencoder에 넣어 또다른 activation values를 뽑아내는 과정을 거치게 됩니다. 따라서 두 가지의 hidden activation values를 활용한 novelty detection을 진행하는 것이 가장 핵심이라고 할 수 있습니다. 자세한 설명은 다음 부분에서 더 진행하도록 하겠습니다.



## 2. Architecture

#### 2-1. Reconstruction based novelty detection

Autoencoder A가 있을 때 encoder를 $g$, decoder $f$라고 하면 $A=f \circ g$로 표현이 가능합니다. 이때 $g$를 통과시킨 값을 latent space라고 하며 autoencoder를 학습시키는 것은 입력값 $x$와 autoencoder를 통과시킨 $A(x)$의 차이, 즉 reconstruction error를 줄이는 것이라고 할 수 있습니다. 따라서 autoencoder를 통해서 정상데이터를 학습시키게 되면 reconstruction error가 줄게 되고 test시에 novelty 데이터가 모델에 들어왔을때 정상값들과는 다른 경향을 보이기 때문에 novelty data를 찾아내는 것이 가능해집니다.  Reconstruction error $\epsilon=\lVert x-A(x)\rVert_2$로 나타나집니다.

Hidden spaces에서의 reconstruction error는 어떻게 될까요? 앞에서 언급한 encoder는 다음과 같이 쪼개질 수 있습니다. $g$가 여러 층으로 이루어져있기 때문에 층 단위로 나누게 된다면 $g=g_l\circ\cdot\cdot\cdot\circ g_1$ 이 되고 특정 i번째 층까지의 encoder 과정은 $g_{:i}=g_i\circ\cdot\cdot\cdot\circ g_1 (1\le i\le l)$로 표현됩니다. 본 식들을 통해서 hidden representations를 뽑아낼 수 있게 됩니다. $\hat{x}=A(x)$라고 하면 hidden representation pairs $(h_i, \hat{h_i})$는 각각 
$$
h_i(x)=g_{:i}(x), \; \; \; \;
\hat{h}_i(x)=g_{:i}(\hat{x})=g_{:i}(A(x))
$$
로 나타나집니다. 

따라서 앞서 언급한 일반적인 reconstruction error는
$$
s_{ord}(H(x))=\lVert h_0(x)-\hat{h}_0(x)\rVert^2_2
$$
로 표현할 수 있게 됩니다. 본 논문에서는 $s_{ord}$에서 더 나아가 $s_{SAP}$, $s_{NAP}$를 도입하면서 hidden representations를 더 잘 활용할 수 있도록 하였습니다.



#### 2-2. Simple aggregation along pathway(SAP)

SAP는 H의 모든 짝들에 대해서 유클리드 거리의 제곱값들을 더한 것을 말합니다. 식으로 표현해보면
$$
s_{SAP}(x)=\sum^l_{i=0}\lVert h_i(x)-\hat{h}_i(x)\rVert^2_2=\lVert\mathbf{h}(x)-\mathbf{\hat{h}}(x)\rVert^2_2
$$
다음과 같습니다. 여기서 굵은 글씨로 적힌 $\mathbf{h}$와 $\hat{\mathbf{h}}$는 각각 $[h_0(x), \cdot\cdot\cdot, h_l(x)]$, $[\hat{h}_0(x), \cdot\cdot\cdot \hat{h}_l(x)]$입니다. 



#### 2-3. Normalized aggregation along pathway(NAP)

2-2의 SAP는 hidden spaces의 속성들을 고려하지 못하기 때문에 또다른 장치가 필요하다고 본 논문은 말하고 있습니다. 그 이유는 H의 pairs에 대한 distance distributions가 각각의 hidden spaces에 따라서 다르기 떄문입니다. 따라서 normalize할 수 있는 방법이 필요하며 이를 orthogonalization과 scaling 방법을 사용하여 진행한 것이 NAP입니다.

$d(x)=\mathbf{h}(x)-\hat{\mathbf{h}}(x)$이고 training set $X$가 주어진다고 설정합니다. 또한 $\mathbf{D}$는 $i$번째 행이 $d(x_i)$를 나타내는 행렬이라고 하고 $\bar{\mathbf{D}}$는 $\mathbf{D}$의 center-wise centered matrix라고 합니다. 이때 $\bar{\mathbf{D}}$는 SVD를 통하여 $\bar{D}=U\Sigma V^\top$로 표현할 수 있습니다. 최종적으로 NAP를 식으로 표현하면 다음과 같습니다. 
$$
s_{NAP}(x)=\lVert(d(x)-\mu_X)^\top V{\Sigma}^{-1}\rVert^2_2
$$
본 식에서 $\mu_X$는 $D$의 column-wise mean을 말합니다.



#### 2-4. Computation

Hidden reconstruction이 어떻게 계산되는지 조금 더 자세하게 살펴보겠습니다. 논문에 따르면 매니폴드 $M_0$는 다음과 같이 정의됩니다.

$$
\forall x \in M_0, x=A(x)
$$

Decoder $\tilde{f}=\tilde{f}_1\circ \cdot \cdot \cdot \circ \tilde{f}_l$를 가정했을때 $\forall x \in M_l, \; \tilde{f}(x)=f(x)$로 표현할 수 있으며 이때 $\tilde{f}$는 encoder $g$와 대칭되고 각 디코더의 레이어는 인코더의 역함수라고 생각해볼 수 있을 것입니다. 즉 $\forall a \in M_i, \; a = (g_i \circ \tilde{f}_i)(a)$라고 할 수 있습니다. 

$\hat{h}'_i(x)=(\tilde{f}_{l:i+1}\circ g_{i+1:})(h_i(x))$이므로 위의 성질들을 활용하면 아래와 같은 식을 도출할 수 있습니다.

$$
\hat{h}'_i(x)=(\tilde{f}_{l:i+1}\circ g_{i+1:})(h_i(x))=(\tilde{f}_{l:i+1}\circ g)(x) \\
=(g_{:i}\circ \tilde{f}\circ g)(x)=(g_{:i}\circ f\circ g)(x)\\
=(g_{:i}\circ A)(x)=h_i(\hat{x})=\hat{h}_i(x)
$$

식을 간단히 해석하면 $\hat{h}'_i(x)=\hat{h}_i(x)$인 것을 알 수 있습니다. 따라서 RaPP의 reconstruction error에 넣어보면

$\sum^l_{i=0} \lVert g_{:i}(x)-\hat{h}'_i(x)\rVert \; = \; \sum^l_{i=0}\lVert g_{:i}(x)-g_{:i}(\hat{x})\rVert$가 됩니다. 수식이 다소 복잡하지만 [그림 1]을 보면서 진행해나가면 큰 어려움은 없을 것 입니다.

<figure>
	<img src="{{ '\assets\images\rapp\1.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [그림 1. RAPP의 기본적 구조 ] </figcaption>
</figure>



## 3. Experiments and Results

Kaggle이나 UCI repository의 데이터를 사용한 실험 혹은 MNIST나 F-MNIST를 사용한 실험 등 여러가지 실험결과들이 있었습니다. 논문에서 실험을 위해서 여러 클래스들에 대해 한 가지 클래스를 novelty, 나머지 클래스들을 normal로 지정하여 실험하는 multimodal normality와 한 가지 클래스를 normal, 나머지 클래스들을 novelty로 지정하여 실험하는 unimodal mormality 두 가지에 대해서 진행을 하였습니다. 그리고 정상데이터를 autoencoder를 통해 학습하고 test과정에서 novelty를 포함한 데이터에서 novelty를 검출하는 실험을 진행하였습니다. 예를들어 MNIST의 경우 0값을 가지는 것을 novelty로 정한 후 나머지 1~9까지의 클래스로 학습을 진행하고 모든 클래스들이 포함된 test data로 novelty detection을 진행합니다. 이때 척도로는 AUROC를 사용하였다고 논문은 밝히고 있습니다. 아래 표에 그 결과값들을 정리해두었습니다.  [그림 3]에서처럼 확실히 hidden activation values를 활용한 $R_APP$모델이 기존의 reconstruction error만 사용한 것보다 15가지의 케이스에 대해서 10가지에서 더 높은 AUROC 값을 보여주는 것을 확인하였습니다. (밑줄부분들의 위치 확인)  또한 NAP를 활용한 VAE가 다른 모델들과 비교하여 가장 좋은 성능을 보여주었습니다.
<figure>
	<img src="{{ '\assets\images\rapp\2-1.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [그림 2. Test Result 1 ] </figcaption>
</figure>

<figure>
	<img src="{{ '\assets\images\rapp\2.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [그림 3. Test Result 2 ] </figcaption>
</figure>
