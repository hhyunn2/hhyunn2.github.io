---
title: "StarGAN 논문 리뷰"
category :
    - Self-supervised learning
tag :
    - Learning representation
toc : true

---

# MoCo

**'Momentum Contrast for Unsupervised Visual Representation Learning'**에 대한 정리입니다.

논문링크: https://arxiv.org/abs/1911.05722



### Intro

BERT나 GPT 등의 language 모델에서는 tokenized dictionaries를 만들때 단어와 같은 discrete한 signal spaces가 있기에 unsupervised한 모델을 적용하기 어렵습니다. 따라서 contrasive loss를 통한 접근이 대두되고 있으며 dynamic dictionaries 만드는 것으로 해결해보려는 것이 하나의 방법입니다. 이 방법을 위해서는 Key가 데이터로부터 샘플링되고 encoder를 통해서 표현됩니다. 그리고 Encoded된 query가 특정 key와 맞아야하고 나머지와는 유사하지 않도록 학습을 진행합니다. 다시 말해서 encoder를 통과한 q가 있을때 encoder를 통과한 key와의 similar 여부를 contrastive loss로 측정하여 similar한 것들을 찾아내는 것이 목표라고 할 수 있겠습니다. 

<figure>
	<img src="{{ '/assets/images/MoCo/moco_model.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 1. MoCo의 기본적인 모델 ] </figcaption>
</figure>

**2가지의 목표** 

1) large and 2) consistent한 dictionary를 만드는 것

**Why?**

- 큰 dictionary가 연속적이고 고차원적인 visual space를 잘 표현할 수 있는 동시에 consistent해야 유사성을 비교할 때 그 비교한 것들 역시 consistent함을 유지할 수 있기 때문

**How?**

- Queue  
- Slowly progressing key encoder



### Method

- InfoNCE

  $$\mathcal{L}_q=-log \frac{exp(q \cdot k_+/\tau)}{\sum^K_{i=0} exp(q \cdot k_i/\tau)}$$

  softmax와 유사, similarity를 통해 positive한 것을 찾고 negative sample들에 대해서는 다르다는 것을 판단하도록

  

- query sample $x^q$가 있을 때 $q=f_q(x^q)$, key 역시 마찬가지로 $k=f_k(x^k)$

- 여기서 $f_q$와 $f_k$를 어떻게 사용하느냐가 중요

<figure>
	<img src="{{ '/assets/images/MoCo/contrastive_methods.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_algo.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result1.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result2.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result3.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result4.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result5.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result6.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>

<figure>
	<img src="{{ '/assets/images/MoCo/moco_result7.png' | prepend: site.baseurl }}" alt=""> 
	<figcaption> [ 그림 2. 3가지의 contrastive loss mechanisms ] </figcaption>
</figure>




