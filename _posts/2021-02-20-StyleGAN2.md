# StyleGAN2

### 1. Intro

- StyleGAN에서는 latent code $z$를 바로 사용하는 대신 mapping network를 통과시켜서 나온 결과물 $w$를 활용하는 방법을 통해 disentanglement를 해결(StyleGAN 논문 참고) 
- 따라서 데이터의 distribution을 linear하게 더 잘 표현할 수 있도록 Generator를 설계



**Problem**

- 기존의 StyleGAN에서 artifacts들을 인지할 수 있음, 즉 어색한 부분들 존재
  - 원인 1: Common blob-like artifacts - design flaw
  - 해결 1: Redesign the normalization
  - 원인 2: Progressive growing 
  - 해결 2: Alternative design - low resolution을 포커스하면서 시작하고 점차 higher



### 2. Method

#### 1) Removing normalization artifacts

**What?**

- 기존의 StyleGAN의 경우 물방울 모양을 하고 있는 blob-shaped aritifacts가 존재



**Why?**

- StyleGAN에서 AdaIN(Adaptive instance normalization)을 통해 각각의 feature map들의 mean과 variance를 normalize. 
- 따라서 상대적인 features의 크기에 따른 정보들을 파괴할 수 있음 
- Instance normalization을 지나면서 Generator가 signal strength information을 의도적으로 빼오는 것이 일어난다고 가설을 세움

- 강한 지역적 spike를 만들어내면서 Generator가 효과적으로 어느 곳에서나 signal을 scale할 수 있음



**Solution?**

- AdaIN을 normalization과 modulation으로 분리



**Procedure?**

- Modulate: $w'_{ijk}=s_i \cdot w_{ijk}$ 

- Input activation이 i.i.d. random variables with unit standard deviation일 때 modulation과 convolution을 거치면 standard deviation $\sigma_j=\sqrt{\sum_{i,k} {w'_{ijk}}^2}$를 갖습니다.

- Demodulate: $w''_{ijk}=w'_{ijk}/\sqrt{\sum_{i,k} {w'_{ijk}}^2 + \epsilon}$ 
- 이러한 demodulation은 instance normalization보다 약함



**Affect?**

- Artifacts는 없애면서 조절능력은 유지
- FID는 영향 별로 없으면서 precision에서 recall로의 이동



#### 2) Image quality and generator smoothness

Updating...



#### 3) Progressive growing revisited

**Why?**

Progressive growing 방식이 기존에 사용되었으나 디테일들에 대한 강한 location preference가 존재해서 더 선호되는 위치로 넘어가지 않고 멈추는 문제가 존재



#### 4) Projection of images to latent space





### 3. Experiments and Results





